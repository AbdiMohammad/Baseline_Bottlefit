datasets:
    ilsvrc2012:
        name: &dataset_name 'ilsvrc2012'
        type: 'ImageFolder'
        root: &root_dir !join ['~/dataset/', *dataset_name]
        splits:
            train:
                dataset_id: &imagenet_train !join [*dataset_name, '/train']
                params:
                    root: !join [*root_dir, '/train']
                    transform_params:
                        0:
                            type: 'RandomResizedCrop'
                            params:
                                size: &input_size [224, 224]
                        1:
                            type: 'RandomHorizontalFlip'
                            params:
                                p: 0.5
                        2: &totensor
                            type: 'ToTensor'
                            params:
                        3: &normalize
                            type: 'Normalize'
                            params:
                                mean: [0.485, 0.456, 0.406]
                                std: [0.229, 0.224, 0.225]
            val:
                dataset_id: &imagenet_val !join [*dataset_name, '/val']
                params:
                    root: !join [*root_dir, '/val']
                    transform_params:
                        0:
                            type: 'Resize'
                            params:
                                size: 256
                        1:
                            type: 'CenterCrop'
                            params:
                                size: *input_size
                        2: *totensor
                        3: *normalize

models:
    teacher_model:
        name: &teacher_model_name 'densenet201'
        params:
            num_classes: 1000
            pretrained: True
        experiment: &teacher_experiment !join [*dataset_name, '-', *teacher_model_name]
        ckpt: !join ['./resource/ckpt/image_classification/teacher/', *teacher_experiment, '.pt']
    student_model:
        name: &student_model_name 'custom_densenet201'
        params:
            bottleneck_channel: &bottleneck_ch 6
            bottleneck_idx: 7
            compressor:
            decompressor:
            num_classes: 1000
            pretrained: True
        experiment: &student_experiment !join [*dataset_name, '-', *student_model_name, '_from_', *teacher_model_name]
        ckpt: !join ['./resource/ckpt/image_classification/multi_stage/ghnd_kd-finetune/', *student_experiment, '-', *bottleneck_ch, 'ch.pt']

train:
    log_freq: 1000
    stage1:
        num_epochs: 10
        train_data_loader:
            dataset_id: *imagenet_train
            random_sample: True
            batch_size: 64
            num_workers: 16
            cache_output:
        val_data_loader:
            dataset_id: *imagenet_val
            random_sample: False
            batch_size: 64
            num_workers: 16
        teacher: &teacher_config
            sequential: ['features']
            frozen_modules: []
            forward_hook:
                input: []
                output: ['features.transition2', 'features.transition3', 'features.denseblock4']
            wrapper:
            requires_grad: False
        student:
            adaptations:
            sequential: ['features.bottleneck', 'features.denseblock3', 'features.transition3', 'features.denseblock4']
            frozen_modules: ['features.denseblock3', 'features.transition3', 'features.denseblock4']
            forward_hook:
                input: []
                output: ['features.bottleneck', 'features.transition3', 'features.denseblock4']
            wrapper: 'DistributedDataParallel'
            requires_grad: True
        apex:
            requires: False
            opt_level: '01'
        optimizer:
            type: 'Adam'
            params:
                lr: 0.001
        scheduler: &scheduler_config
            type: 'MultiStepLR'
            params:
                milestones: [5]
                gamma: 0.1
        criterion: &criterion_config
            type: 'GeneralizedCustomLoss'
            org_term:
                factor: 0.0
            sub_terms:
                transition2:
                    criterion:
                        type: 'MSELoss'
                        params:
                            reduction: 'sum'
                    params:
                        input:
                            is_from_teacher: False
                            module_path: 'features.bottleneck'
                            io: 'output'
                        target:
                            is_from_teacher: True
                            module_path: 'features.transition2'
                            io: 'output'
                    factor: 1.0
                transition3:
                    criterion:
                        type: 'MSELoss'
                        params:
                            reduction: 'sum'
                    params:
                        input:
                            is_from_teacher: False
                            module_path: 'features.transition3'
                            io: 'output'
                        target:
                            is_from_teacher: True
                            module_path: 'features.transition3'
                            io: 'output'
                    factor: 1.0
                denseblock4:
                    criterion:
                        type: 'MSELoss'
                        params:
                            reduction: 'sum'
                    params:
                        input:
                            is_from_teacher: False
                            module_path: 'features.denseblock4'
                            io: 'output'
                        target:
                            is_from_teacher: True
                            module_path: 'features.denseblock4'
                            io: 'output'
                    factor: 1.0
    stage2:
        num_epochs: 10
        teacher:
            sequential: []
            forward_hook:
                input: []
                output: []
            wrapper:
            requires_grad: False
        student:
            adaptations:
            sequential: []
            frozen_modules: ['features.bottleneck.encoder']
            forward_hook:
                input: []
                output: []
            wrapper: 'DistributedDataParallel'
            requires_grad: True
        apex:
            requires: False
            opt_level: '01'
        optimizer:
            type: 'SGD'
            params:
                lr: 0.001
                momentum: 0.9
                weight_decay: 0.0005
        scheduler:
            type: 'MultiStepLR'
            params:
                milestones: [5]
                gamma: 0.1
        criterion:
            type: 'GeneralizedCustomLoss'
            org_term:
                criterion:
                    type: 'KDLoss'
                    params:
                        temperature: 1.0
                        alpha: 0.5
                        reduction: 'batchmean'
                factor: 1.0
            sub_terms:

test:
    test_data_loader:
        dataset_id: *imagenet_val
        random_sample: False
        batch_size: 1
        num_workers: 16

