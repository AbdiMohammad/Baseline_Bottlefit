datasets:
    ilsvrc2012:
        name: &dataset_name 'ilsvrc2012'
        type: 'imagefolder'
        root: &root_dir !join ['./resource/dataset/', *dataset_name]
        rough_size: 256
        input_size: [224, 224]
        splits:
            train:
                dataset_id: &imagenet_train !join [*dataset_name, '/train']
                images: !join [*root_dir, '/train']
                data_aug: True
            val:
                dataset_id: &imagenet_val !join [*dataset_name, '/val']
                images: !join [*root_dir, '/val']
                data_aug: False
        normalizer:
            mean: [0.485, 0.456, 0.406]
            std: [0.229, 0.224, 0.225]

models:
    teacher_model:
        name: &teacher_model_name 'resnet34'
        params:
            num_classes: 1000
            pretrained: True
        experiment: &teacher_experiment !join [*dataset_name, '-', *teacher_model_name]
        ckpt: !join ['./resource/ckpt/teacher/', *teacher_experiment, '.pt']

    student_model:
        name: &student_model_name 'resnet18'
        params:
            num_classes: 1000
            pretrained: True
        experiment: &student_experiment !join [*dataset_name, '-', *student_model_name, '_from_', *teacher_model_name]
        ckpt: !join ['./resource/ckpt/single_stage/at/', *student_experiment, '.pt']

train:
    log_freq: 1000
    num_epochs: 20
    train_data_loader:
        dataset_id: *imagenet_train
        random_sample: True
        batch_size: 32
        num_workers: 16
        cache_output:
    val_data_loader:
        dataset_id: *imagenet_val
        random_sample: False
        batch_size: 32
        num_workers: 16
    teacher:
        sequential: []
        forward_hook:
            input: []
            output: ['layer1', 'layer2', 'layer3', 'layer4']
        wrapper:
        requires_grad: False
    student:
        adaptations:
        sequential: []
        frozen_modules: []
        forward_hook:
            input: []
            output: ['layer1', 'layer2', 'layer3', 'layer4']
        wrapper:
        requires_grad: True
    apex:
        requires: False
        opt_level: '01'
    optimizer:
        type: 'Adam'
        params:
            lr: 0.0001
    scheduler:
        type: 'MultiStepLR'
        params:
            milestones: [5, 15]
            gamma: 0.1
    criterion:
        type: 'GeneralizedCustomLoss'
        org_term:
            criterion:
                type: 'KDLoss'
                params:
                    temperature: 1.0
                    alpha: 1.0
                    reduction: 'batchmean'
            factor: 1.0
        sub_terms:
            at_loss:
                criterion:
                    type: 'ATLoss'
                    params:
                        at_pairs:
                            pair1:
                                teacher:
                                    output: 'layer1'
                                student:
                                    output: 'layer1'
                                factor: 1
                            pair2:
                                teacher:
                                    output: 'layer2'
                                student:
                                    output: 'layer2'
                                factor: 1
                            pair3:
                                teacher:
                                    output: 'layer3'
                                student:
                                    output: 'layer3'
                                factor: 1
                            pair4:
                                teacher:
                                    output: 'layer4'
                                student:
                                    output: 'layer4'
                                factor: 1
                        reduction: 'mean'
                factor: 1000.0

test:
    test_data_loader:
        dataset_id: *imagenet_val
        random_sample: False
        batch_size: 1
        num_workers: 16
