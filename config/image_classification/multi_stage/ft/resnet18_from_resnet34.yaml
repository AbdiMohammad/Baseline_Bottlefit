datasets:
    ilsvrc2012:
        name: &dataset_name 'ilsvrc2012'
        type: 'imagefolder'
        root: &root_dir !join ['./resource/dataset/', *dataset_name]
        rough_size: 256
        input_size: [224, 224]
        splits:
            train:
                dataset_id: &imagenet_train !join [*dataset_name, '/train']
                images: !join [*root_dir, '/train']
                data_aug: True
            val:
                dataset_id: &imagenet_val !join [*dataset_name, '/val']
                images: !join [*root_dir, '/val']
                data_aug: False
        normalizer:
            mean: [0.485, 0.456, 0.406]
            std: [0.229, 0.224, 0.225]

models:
    teacher_model: &teacher_model
        name: &teacher_model_name 'resnet34'
        params:
            num_classes: 1000
            pretrained: True
        experiment: &teacher_experiment !join [*dataset_name, '-', *teacher_model_name]
        ckpt: !join ['./resource/ckpt/teacher/', *teacher_experiment, '.pt']

    student_model:
        name: &student_model_name 'resnet18'
        params:
            num_classes: 1000
            pretrained: True
        experiment: &student_experiment !join [*dataset_name, '-', *student_model_name, '_from_', *teacher_model_name]
        ckpt: !join ['./resource/ckpt/multi_stage/ft/', *student_experiment, '.pt']

train:
    log_freq: 1000
    stage1:
        num_epochs: 1
        train_data_loader:
            dataset_id: *imagenet_train
            random_sample: True
            batch_size: 32
            num_workers: 16
            cache_output:
        val_data_loader:
            dataset_id: *imagenet_val
            random_sample: False
            batch_size: 32
            num_workers: 16
        teacher:
            special:
                type: 'EmptyModule'
                params:
            sequential: []
            forward_hook:
                input: []
                output: []
            wrapper:
            requires_grad: False
        student:
            adaptations:
            sequential: []
            special: &teacher4ft
                type: 'Teacher4FactorTransfer'
                params:
                    base_model_config: *teacher_model
                    input_module_path: 'teacher_model.layer4'
                    paraphraser_params_config:
                        k: 0.5
                        num_input_channels: 512
                        kernel_size: 3
                        stride: 1
                        padding: 1
                        uses_bn: True
                    paraphraser_ckpt: !join ['./resource/ckpt/multi_stage/ft/', *student_experiment, '_paraphraser.pt']
            forward_hook:
                input: []
                output: ['teacher_model.layer4', 'paraphraser']
            wrapper:
            requires_grad: True
            frozen_modules: ['teacher_model.conv1', 'teacher_model.relu', 'teacher_model.maxpool', 'teacher_model.layer1', 'teacher_model.layer2', 'teacher_model.layer3', 'teacher_model.layer4', 'teacher_model.fc']
        apex:
            requires: False
            opt_level: '01'
        optimizer:
            type: 'SGD'
            params:
                lr: 0.0001
                momentum: 0.9
                weight_decay: 0.0005
        criterion:
            type: 'GeneralizedCustomLoss'
            org_term:
                factor: 0.0
            sub_terms:
                reconst:
                    criterion:
                        type: 'MSELoss'
                        params:
                            reduction: 'sum'
                    params:
                        input:
                            is_from_teacher: False
                            module_path: 'paraphraser'
                            io: 'output'
                        target:
                            is_from_teacher: False
                            module_path: 'teacher_model.layer4'
                            io: 'output'
                    factor: 1.0
    stage2:
        num_epochs: 15
        teacher:
            sequential: []
            special: *teacher4ft
            forward_hook:
                input: []
                output: ['teacher_model.layer4', 'paraphraser']
            wrapper:
            requires_grad: False
        student:
            adaptations:
            sequential: []
            special:
                type: 'Student4FactorTransfer'
                params:
                    input_module_path: 'student_model.layer4'
                    translator_params_config:
                        num_input_channels: 512
                        num_output_channels: 256
                        kernel_size: 3
                        stride: 1
                        padding: 1
                        uses_bn: True
            forward_hook:
                input: []
                output: ['student_model.layer4', 'translator']
            wrapper:
            requires_grad: True
            frozen_modules: []
        apex:
            requires: False
            opt_level: '01'
        optimizer:
            type: 'SGD'
            params:
                lr: 0.0001
                momentum: 0.9
                weight_decay: 0.0005
        scheduler:
            type: 'MultiStepLR'
            params:
                milestones: [5, 10]
                gamma: 0.1
        criterion:
            type: 'GeneralizedCustomLoss'
            org_term:
                criterion:
                    type: 'KDLoss'
                    params:
                        temperature: 1.0
                        alpha: 1.0
                        reduction: 'batchmean'
                factor: 1.0
            sub_terms:
                factor_transfer:
                    criterion:
                        type: 'FTLoss'
                        params:
                            p: 1
                            reduction: 'batchmean'
                            paraphraser:
                                module_path: 'paraphraser'
                            translator_path: 'translator'
                    factor: 1000.0

test:
    test_data_loader:
        dataset_id: *imagenet_val
        random_sample: False
        batch_size: 1
        num_workers: 16
