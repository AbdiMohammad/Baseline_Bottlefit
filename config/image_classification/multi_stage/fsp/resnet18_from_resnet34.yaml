datasets:
    ilsvrc2012:
        name: &dataset_name 'ilsvrc2012'
        type: 'imagefolder'
        root: &root_dir !join ['./resource/dataset/', *dataset_name]
        rough_size: 256
        input_size: [224, 224]
        splits:
            train:
                dataset_id: &imagenet_train !join [*dataset_name, '/train']
                images: !join [*root_dir, '/train']
                data_aug: True
            val:
                dataset_id: &imagenet_val !join [*dataset_name, '/val']
                images: !join [*root_dir, '/val']
                data_aug: False
        normalizer:
            mean: [0.485, 0.456, 0.406]
            std: [0.229, 0.224, 0.225]

models:
    teacher_model:
        name: &teacher_model_name 'resnet34'
        params:
            num_classes: 1000
            pretrained: True
        experiment: &teacher_experiment !join [*dataset_name, '-', *teacher_model_name]
        ckpt: !join ['./resource/ckpt/teacher/', *teacher_experiment, '.pt']

    student_model:
        name: &student_model_name 'resnet18'
        params:
            num_classes: 1000
            pretrained: True
        experiment: &student_experiment !join [*dataset_name, '-', *student_model_name, '_from_', *teacher_model_name]
        ckpt: !join ['./resource/ckpt/multi_stage/fsp/', *student_experiment, '.pt']

train:
    log_freq: 1000
    stage1:
        num_epochs: 10
        train_data_loader:
            dataset_id: *imagenet_train
            random_sample: True
            batch_size: 32
            num_workers: 16
        val_data_loader:
            dataset_id: *imagenet_val
            random_sample: False
            batch_size: 32
            num_workers: 16
        apex:
            requires: False
            opt_level: '01'
        teacher:
            sequential: ['conv1', 'relu', 'maxpool', 'layer1', 'layer2', 'layer3', 'layer4']
            forward_hook:
                input: ['layer1', 'layer2.1', 'layer3.1', 'layer4.1']
                output: ['layer1', 'layer2', 'layer3', 'layer4']
            wrapper:
            requires_grad: False
        student:
            adaptations:
            sequential: ['conv1', 'relu', 'maxpool', 'layer1', 'layer2', 'layer3', 'layer4']
            frozen_modules: []
            forward_hook:
                input: ['layer1', 'layer2.1', 'layer3.1', 'layer4.1']
                output: ['layer1', 'layer2', 'layer3', 'layer4']
            wrapper:
            requires_grad: True
        optimizer:
            type: 'Adam'
            params:
                lr: 0.0001
        scheduler:
            type: 'MultiStepLR'
            params:
                milestones: [5]
                gamma: 0.1
        criterion:
            type: 'GeneralizedCustomLoss'
            org_term:
                factor: 0.0
            sub_terms:
                layer1:
                    criterion:
                        type: 'FSPLoss'
                        params:
                            fsp_pairs:
                                pair1:
                                    teacher_first:
                                        input: 'layer1'
                                    teacher_second:
                                        output: 'layer1'
                                    student_first:
                                        input: 'layer1'
                                    student_second:
                                        output: 'layer1'
                                    factor: 1
                                pair2:
                                    teacher_first:
                                        input: 'layer2.1'
                                    teacher_second:
                                        output: 'layer2'
                                    student_first:
                                        input: 'layer2.1'
                                    student_second:
                                        output: 'layer2'
                                    factor: 1
                                pair3:
                                    teacher_first:
                                        input: 'layer3.1'
                                    teacher_second:
                                        output: 'layer3'
                                    student_first:
                                        input: 'layer3.1'
                                    student_second:
                                        output: 'layer3'
                                    factor: 1
                                pair4:
                                    teacher_first:
                                        input: 'layer4.1'
                                    teacher_second:
                                        output: 'layer4'
                                    student_first:
                                        input: 'layer4.1'
                                    student_second:
                                        output: 'layer4'
                                    factor: 1
                    factor: 1.0
    stage2:
        num_epochs: 10
        apex:
            requires: False
            opt_level: '01'
        teacher:
            sequential: []
            wrapper: 'DistributedDataParallel'
            requires_grad: False
        student:
            adaptations:
            sequential: []
            wrapper: 'DistributedDataParallel'
            requires_grad: True
            frozen_modules: []
        optimizer:
            type: 'SGD'
            params:
                lr: 0.0001
                momentum: 0.9
                weight_decay: 0.0005
        scheduler:
            type: 'MultiStepLR'
            params:
                milestones: [5]
                gamma: 0.1
        criterion:
            type: 'GeneralizedCustomLoss'
            org_term:
                criterion:
                    type: 'KDLoss'
                    params:
                        temperature: 1.0
                        alpha: 1.0
                        reduction: 'batchmean'
                factor: 1.0
            sub_terms:

test:
    test_data_loader:
        dataset_id: *imagenet_val
        random_sample: False
        batch_size: 1
        num_workers: 16
