datasets:
    ilsvrc2012:
        name: &dataset_name 'ilsvrc2012'
        type: 'imagefolder'
        root: &root_dir !join ['./resource/dataset/', *dataset_name]
        rough_size: 256
        input_size: [224, 224]
        splits:
            train:
                dataset_id: &imagenet_train !join [*dataset_name, '/train']
                images: !join [*root_dir, '/train']
                data_aug: True
            val:
                dataset_id: &imagenet_val !join [*dataset_name, '/val']
                images: !join [*root_dir, '/val']
                data_aug: False
        normalizer:
            mean: [0.485, 0.456, 0.406]
            std: [0.229, 0.224, 0.225]

models:
    teacher_model:
        name: &teacher_model_name 'resnet152'
        params:
            num_classes: 1000
            pretrained: True
        experiment: &teacher_experiment !join [*dataset_name, '-', *teacher_model_name]
        ckpt: !join ['./resource/ckpt/teacher/', *teacher_experiment, '.pt']

    student_model:
        name: &student_model_name 'resnet18'
        params:
            num_classes: 1000
            pretrained: True
        experiment: &student_experiment !join [*dataset_name, '-', *student_model_name, '_from_', *teacher_model_name]
        ckpt: !join ['./resource/ckpt/multi_stage/fitnet/', *student_experiment, '.pt']

train:
    log_freq: 1000
    stage1:
        num_epochs: 5
        train_data_loader:
            dataset_id: *imagenet_train
            random_sample: True
            batch_size: 32
            num_workers: 16
            cache_output:
        val_data_loader:
            dataset_id: *imagenet_val
            random_sample: False
            batch_size: 32
            num_workers: 16
        teacher:
            sequential: ['conv1', 'relu', 'maxpool', 'layer1']
            forward_hook:
                input: []
                output: ['layer1']
            wrapper:
            requires_grad: False
        student:
            adaptations:
                convreg:
                    type: 'ConvReg'
                    params:
                        num_input_channels: 64
                        num_output_channels: 256
                        kernel_size: 1
                        stride: 1
                        padding: 0
                        uses_relu: True
            sequential: ['conv1', 'relu', 'maxpool', 'layer1', '+convreg']
            frozen_modules: []
            forward_hook:
                input: []
                output: ['+convreg']
            wrapper:
            requires_grad: True
        apex:
            requires: False
            opt_level: '01'
        optimizer:
            type: 'Adam'
            params:
                lr: 0.001
        scheduler:
            type: 'MultiStepLR'
            params:
                milestones: [3]
                gamma: 0.1
        criterion:
            type: 'GeneralizedCustomLoss'
            org_term:
                factor: 0.0
            sub_terms:
                layer1:
                    criterion:
                        type: 'MSELoss'
                        params:
                            reduction: 'sum'
                    params:
                        input:
                            is_from_teacher: False
                            module_path: '+convreg'
                            io: 'output'
                        target:
                            is_from_teacher: True
                            module_path: 'layer1'
                            io: 'output'
                    factor: 1.0
    stage2:
        num_epochs: 15
        teacher:
            sequential: []
            wrapper: 'DistributedDataParallel'
            requires_grad: False
        student:
            adaptations:
            sequential: []
            wrapper: 'DistributedDataParallel'
            requires_grad: True
            frozen_modules: []
        apex:
            requires: False
            opt_level: '01'
        optimizer:
            type: 'SGD'
            params:
                lr: 0.0001
                momentum: 0.9
                weight_decay: 0.0005
        scheduler:
            type: 'MultiStepLR'
            params:
                milestones: [5, 10]
                gamma: 0.1
        criterion:
            type: 'GeneralizedCustomLoss'
            org_term:
                criterion:
                    type: 'KDLoss'
                    params:
                        temperature: 1.0
                        alpha: 0.5
                        reduction: 'batchmean'
                factor: 1.0
            sub_terms:

test:
    test_data_loader:
        dataset_id: *imagenet_val
        random_sample: False
        batch_size: 1
        num_workers: 16
